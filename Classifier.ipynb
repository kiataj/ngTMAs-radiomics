{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb0a62b-ef07-4a08-ac34-c23a80e5c498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Matplotlib customization\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# Scikit-learn tools\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve, accuracy_score, f1_score, \n",
    "    precision_score, recall_score\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GroupKFold, StratifiedKFold, cross_validate, GridSearchCV\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# PyTorch for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Skorch for PyTorch integration with Scikit-learn\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import LRScheduler\n",
    "\n",
    "# UMAP for dimensionality reduction\n",
    "from umap import UMAP\n",
    "\n",
    "# SHAP for model interpretability\n",
    "import shap\n",
    "\n",
    "# Plotly for interactive visualization\n",
    "import plotly.express as px\n",
    "\n",
    "# Custom modules\n",
    "from tmaR import classifiers, FeatureProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da8a42-b7fa-47ce-ab5e-9226b92b2461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StratifiedGroupKFold:\n",
    "    def __init__(self, n_splits=5, shuffle=False, random_state=None):\n",
    "        self.n_splits = n_splits\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def split(self, X, y, groups):\n",
    "        \"\"\"\n",
    "        Stratified Group K-Fold splitting.\n",
    "        \n",
    "        Parameters:\n",
    "        X: array-like, shape (n_samples, n_features) - Feature matrix.\n",
    "        y: array-like, shape (n_samples,) - Target labels.\n",
    "        groups: array-like, shape (n_samples,) - Group identifiers.\n",
    "\n",
    "        Yields:\n",
    "        train_idx, test_idx - Indices for train and test splits.\n",
    "        \"\"\"\n",
    "        groups = np.array(groups)  # Ensure groups is a NumPy array\n",
    "        y = np.array(y)  # Ensure y is a NumPy array\n",
    "        unique_groups = np.unique(groups)\n",
    "\n",
    "        if self.shuffle:\n",
    "            rng = np.random.RandomState(self.random_state)\n",
    "            rng.shuffle(unique_groups)\n",
    "\n",
    "        # Assign a label to each group based on the majority label in `y`\n",
    "        group_labels = {group: np.argmax(np.bincount(y[np.where(groups == group)])) for group in unique_groups}\n",
    "\n",
    "        stratified_labels = np.array([group_labels[group] for group in groups])\n",
    "\n",
    "        strat_kfold = StratifiedKFold(n_splits=self.n_splits, shuffle=self.shuffle, random_state=self.random_state)\n",
    "        \n",
    "        for train_group_idx, test_group_idx in strat_kfold.split(unique_groups, [group_labels[g] for g in unique_groups]):\n",
    "            train_groups, test_groups = unique_groups[train_group_idx], unique_groups[test_group_idx]\n",
    "\n",
    "            train_idx = np.where(np.isin(groups, train_groups))[0]\n",
    "            test_idx = np.where(np.isin(groups, test_groups))[0]\n",
    "\n",
    "            yield train_idx, test_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a8b5b-0eaa-4b7d-b91a-ceb2a28cad61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_rate=0.5):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            input_dim : int\n",
    "                Dimensionality of the input (e.g., 143)\n",
    "            hidden_dim : int\n",
    "                Size of the hidden layer (must be divisible by num_tokens)\n",
    "            output_dim : int\n",
    "                Number of classes (k)\n",
    "            num_tokens : int (default=8)\n",
    "                Number of tokens to split the hidden representation into.\n",
    "            dropout_rate : float (default=0.5)\n",
    "                Dropout probability to prevent overfitting.\n",
    "                \n",
    "        This model is an MLP with:\n",
    "        - Batch Normalization for stable training\n",
    "        - Dropout for regularization\n",
    "        - Fully connected layers for classification\n",
    "        \"\"\"\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        \n",
    "        # First fully connected layer\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)  # Dropout after activation\n",
    "        \n",
    "        # Second fully connected layer (classification layer)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # First FC layer with ReLU, Batch Norm, and Dropout\n",
    "        h = self.fc1(x)  # Linear transformation\n",
    "        h = F.relu(h)  # Activation function\n",
    "        h = self.dropout1(h)  # Apply Dropout\n",
    "        \n",
    "        # Final classification layer\n",
    "        out = self.fc2(h)  # (B, output_dim)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969e4e2f-c6f7-4c29-94ac-1cddf28c1520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FC(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.5):\n",
    "        \"\"\"\n",
    "        A simple MLP with no hidden layer.\n",
    "\n",
    "        Parameters:\n",
    "            input_dim : int\n",
    "                Dimensionality of the input (e.g., 143)\n",
    "            output_dim : int\n",
    "                Number of classes (k)\n",
    "            dropout_rate : float (default=0.5)\n",
    "                Dropout probability to prevent overfitting.\n",
    "        \"\"\"\n",
    "        super(FC, self).__init__()\n",
    "\n",
    "        # Dropout before classification\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # Directly map input to output\n",
    "        self.fc_out = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply dropout before the classification layer\n",
    "        x = self.dropout(x)\n",
    "        out = self.fc_out(x)  # (B, output_dim)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f8e9cb-1eb7-4e22-9e91-75b1b4d36154",
   "metadata": {},
   "source": [
    "#### Diagnosen revidiert kodiert: \n",
    "<br>Papillär classic=1, \n",
    "<br>Papillär follikuläre Variante=2, \n",
    "<br>Papillär poorly diff. Anteil=3, \n",
    "<br>Follikulär minimally invasive=4, \n",
    "<br>Follikulär widely invasive=5, \n",
    "<br>Papilläres Karzinom spezielle Variante=6,\n",
    "<br>Follikulär onkozytär minimally invasive=7,\n",
    "<br>Follikulär onkozytär widely invasive=8,\n",
    "<br>Follikulär poorly diff. Anteil=9,\n",
    "<br>Follikuläres onkozytäres Adenom=10,\n",
    "<br>follikulär poorly differentiated onkozytär=11,\n",
    "<br>Follikuläres Adenom=12\n",
    "<br>Normal tissue=13\n",
    "<br>Nodular Hyperplasia=15\n",
    "<br>Medullary thyroid carcinoma=14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef58fe44-e085-40b3-8894-7b751506de14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r processed_radiomics\n",
    "%store -r meta_data\n",
    "df = processed_radiomics\n",
    "\n",
    "# Filter data for tissue type and drop NaN values\n",
    "label = 'tissue'\n",
    "\n",
    "df = df.reindex(meta_data.index)\n",
    "\n",
    "# Filter by tissue type if label is not 'tissue'\n",
    "if label not in ['tissue']:\n",
    "    valid_indices = meta_data[meta_data['tissue'] == 1].index\n",
    "    meta_data = meta_data.loc[valid_indices]\n",
    "    df = df.loc[valid_indices]\n",
    "\n",
    "# Drop rows with NaN values in the label column\n",
    "meta_data = meta_data.dropna(subset=[label])\n",
    "meta_data = meta_data[~meta_data['ID'].isin([734, 560, 654])]\n",
    "df = df.loc[meta_data.index]\n",
    "\n",
    "if label == 'Diagnosis':\n",
    "    meta_data[label] = meta_data[label].replace({1: 0, 2:0, 6:0}) # remapping some classes to simplify the problem\n",
    "    meta_data[label] = meta_data[label].replace({4:1,5:1,12:1}) #FTC\n",
    "    meta_data[label] = meta_data[label].replace({3: 2, 9:2, 11:2})  #Poorly\n",
    "    meta_data[label] = meta_data[label].replace({7: 3, 8:3, 10:3}) #Onkozytar\n",
    "    #meta_data[label] = meta_data[label].replace({4:2}) #Onkozytar\n",
    "    \n",
    "    # Remove unwanted labels\n",
    "    exclude_labels = [2,3,13,14,15]\n",
    "    meta_data = meta_data[~meta_data[label].isin(exclude_labels)]\n",
    "    meta_data = meta_data.dropna(subset=[label])\n",
    "    df = df.loc[meta_data.index]\n",
    "    \n",
    "if label in ['BRAF', 'BRAF_2nd', 'BRAF_combi']:\n",
    "    indices = meta_data[meta_data['Diagnosis'].isin([1,2,3,6,7,8,9,10,11,14])].index\n",
    "    meta_data = meta_data.loc[indices]\n",
    "    df = df.loc[indices]\n",
    "\n",
    "if label in ['RAS']:\n",
    "    #indices = meta_data[meta_data['Diagnosis'].isin([4,5,9,12,2])].index #uncomment for Follicular tumors only\n",
    "    indices = meta_data[meta_data['Diagnosis'].isin([1,2,3,4,5,6,7,8,9,10,11,12,14])].index #uncomment for including all tumors in RAS classification\n",
    "    meta_data = meta_data.loc[indices]\n",
    "    df = df.loc[indices]\n",
    "    \n",
    "if label in ['Relapse']:\n",
    "    meta_data = meta_data[~meta_data['TMA'].isin([2406])]\n",
    "    df = df.loc[meta_data.index]\n",
    "    \n",
    "\n",
    "label_df = meta_data[label].astype(int)\n",
    "\n",
    "path = f\"J:\\\\TMAs\\\\Radiomics_v6\\\\Results_final\\\\{label}\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2f14c9-ed58-4a97-8494-dc61ad6330d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique classes and their counts\n",
    "unique_classes, class_counts = np.unique(label_df, return_counts=True)\n",
    "\n",
    "# Print unique classes\n",
    "print(f\"List of unique classes: {unique_classes}\")\n",
    "\n",
    "# Print number of samples per class\n",
    "for cls, count in zip(unique_classes, class_counts):\n",
    "    print(f\"Class {cls}: {count} samples\")\n",
    "\n",
    "# Store results in a dictionary (optional)\n",
    "class_distribution = dict(zip(unique_classes, class_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d26d0c-d0ab-4f10-8dce-476b917ee64b",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820369bf-084f-458d-8478-4dd0294bcee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Training and Model Parameters\n",
    "# ------------------------------\n",
    "num_epochs = 10\n",
    "batch_size = 16\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-3\n",
    "dropout_rate=0.1\n",
    "gamma = 0.9\n",
    "\n",
    "n_splits = 5\n",
    "group_kfold = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "# Assume df is your features DataFrame and label_df contains your labels.\n",
    "input_dim = df.shape[1]\n",
    "hidden_dim = 256 #simpleMLP does not have a hidden layer\n",
    "output_dim = 2  # binary classification\n",
    "\n",
    "# Define class weights (if needed) and device\n",
    "class_weights = torch.tensor([1, 1], dtype=torch.float32)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# ------------------------------\n",
    "# Create the skorch NeuralNetClassifier\n",
    "# ------------------------------\n",
    "net = NeuralNetClassifier(\n",
    "    module=MLP,\n",
    "    module__input_dim=input_dim,\n",
    "    module__hidden_dim=hidden_dim,\n",
    "    module__output_dim=output_dim,\n",
    "    module__dropout_rate=dropout_rate,\n",
    "    max_epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    optimizer=optim.Adam,\n",
    "    optimizer__lr=learning_rate,\n",
    "    optimizer__weight_decay=weight_decay,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    criterion__weight=class_weights,\n",
    "    device=device,\n",
    "    # Use an exponential learning rate scheduler callback\n",
    "    callbacks=[('lr_scheduler', LRScheduler(policy='ExponentialLR', gamma=gamma))],\n",
    "    # We use external cross-validation so disable internal train/validation split.\n",
    "    train_split=None,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# Create the sklearn Pipeline\n",
    "# ------------------------------\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('net', net)\n",
    "])\n",
    "\n",
    "# ------------------------------\n",
    "# Data Preparation\n",
    "# ------------------------------\n",
    "# Convert data to numpy arrays (assumed float32 for features and int64 for labels)\n",
    "X = df.values.astype(np.float32)\n",
    "y = label_df.values.astype(np.int64)\n",
    "groups = meta_data['PID'].values  # grouping variable\n",
    "\n",
    "# ------------------------------\n",
    "# Initialize Lists for Metrics and ROC Curves\n",
    "# ------------------------------\n",
    "fold_train_losses     = []\n",
    "fold_train_aucs       = []\n",
    "fold_train_accuracies = []\n",
    "fold_train_f1s        = []\n",
    "fold_train_precision  = []\n",
    "fold_train_recall     = []\n",
    "\n",
    "fold_val_losses       = []\n",
    "fold_val_aucs         = []\n",
    "fold_val_accuracies   = []\n",
    "fold_val_f1s          = []\n",
    "fold_val_precision    = []\n",
    "fold_val_recall       = []\n",
    "\n",
    "roc_curves_train      = []  # list of tuples: (fpr, tpr) per fold\n",
    "roc_curves_val        = []\n",
    "\n",
    "all_train_probs_1_list = []\n",
    "all_val_probs_1_list   = []\n",
    "all_train_targets_list = []\n",
    "all_val_targets_list   = []\n",
    "\n",
    "global_pos_low_confidence = []  # indices of true positives with low confidence (< 0.5)\n",
    "global_neg_high_confidence = []  # indices of true negatives with high confidence (>= 0.5)\n",
    "\n",
    "# ------------------------------\n",
    "# Function to Compute Loss on a Dataset\n",
    "# ------------------------------\n",
    "def compute_loss(model, X_data, y_data):\n",
    "    model.eval()\n",
    "    X_tensor = torch.tensor(X_data, dtype=torch.float32).to(device)\n",
    "    y_tensor = torch.tensor(y_data, dtype=torch.long).to(device)\n",
    "    outputs = model(X_tensor)\n",
    "    loss = nn.CrossEntropyLoss(weight=class_weights)(outputs, y_tensor).item()\n",
    "    return loss\n",
    "\n",
    "# ------------------------------\n",
    "# Cross-Validation Loop\n",
    "# ------------------------------\n",
    "for fold, (train_idx, val_idx) in enumerate(group_kfold.split(X, y, groups)):\n",
    "    print(f\"Fold {fold+1}/{n_splits}\")\n",
    "    \n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_val, y_val     = X[val_idx], y[val_idx]\n",
    "    \n",
    "    # Fit the pipeline on the training split.\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # The scaler is part of the pipeline so transform X for loss computation.\n",
    "    X_train_scaled = pipeline.named_steps['scaler'].transform(X_train)\n",
    "    X_val_scaled   = pipeline.named_steps['scaler'].transform(X_val)\n",
    "    \n",
    "    # Get the trained PyTorch model from skorch.\n",
    "    trained_model = pipeline.named_steps['net'].module_\n",
    "    \n",
    "    # Compute training and validation losses.\n",
    "    train_loss = compute_loss(trained_model, X_train_scaled, y_train)\n",
    "    val_loss   = compute_loss(trained_model, X_val_scaled, y_val)\n",
    "    \n",
    "    # Obtain predictions and probabilities.\n",
    "    train_probs = pipeline.predict_proba(X_train)\n",
    "    train_preds = pipeline.predict(X_train)\n",
    "    val_probs   = pipeline.predict_proba(X_val)\n",
    "    val_preds   = pipeline.predict(X_val)\n",
    "    \n",
    "    # Store targets and probabilities (for later histograms).\n",
    "    all_train_targets_list.append(y_train)\n",
    "    all_val_targets_list.append(y_val)\n",
    "    all_train_probs_1_list.append(train_probs[:, 1])\n",
    "    all_val_probs_1_list.append(val_probs[:, 1])\n",
    "    \n",
    "    # Compute performance metrics.\n",
    "    train_auc  = roc_auc_score(y_train, train_probs[:, 1])\n",
    "    train_acc  = accuracy_score(y_train, train_preds)\n",
    "    train_f1   = f1_score(y_train, train_preds, average='weighted')\n",
    "    train_prec = precision_score(y_train, train_preds, average='weighted')\n",
    "    train_rec  = recall_score(y_train, train_preds, average='weighted')\n",
    "    \n",
    "    val_auc  = roc_auc_score(y_val, val_probs[:, 1])\n",
    "    val_acc  = accuracy_score(y_val, val_preds)\n",
    "    val_f1   = f1_score(y_val, val_preds, average='weighted')\n",
    "    val_prec = precision_score(y_val, val_preds, average='weighted')\n",
    "    val_rec  = recall_score(y_val, val_preds, average='weighted')\n",
    "    \n",
    "    # Save metrics per fold.\n",
    "    fold_train_losses.append(train_loss)\n",
    "    fold_train_aucs.append(train_auc)\n",
    "    fold_train_accuracies.append(train_acc)\n",
    "    fold_train_f1s.append(train_f1)\n",
    "    fold_train_precision.append(train_prec)\n",
    "    fold_train_recall.append(train_rec)\n",
    "    \n",
    "    fold_val_losses.append(val_loss)\n",
    "    fold_val_aucs.append(val_auc)\n",
    "    fold_val_accuracies.append(val_acc)\n",
    "    fold_val_f1s.append(val_f1)\n",
    "    fold_val_precision.append(val_prec)\n",
    "    fold_val_recall.append(val_rec)\n",
    "    \n",
    "    # Compute ROC curves for both training and validation.\n",
    "    train_fpr, train_tpr, _ = roc_curve(y_train, train_probs[:, 1])\n",
    "    roc_curves_train.append((train_fpr, train_tpr))\n",
    "    val_fpr, val_tpr, _ = roc_curve(y_val, val_probs[:, 1])\n",
    "    roc_curves_val.append((val_fpr, val_tpr))\n",
    "    \n",
    "    # Identify misclassified low-confidence predictions on the validation set.\n",
    "    pos_low_conf = []  # true positive samples with predicted probability for class 1 < 0.5\n",
    "    neg_high_conf = [] # true negative samples with predicted probability for class 1 >= 0.5\n",
    "    for idx, gt, prob in zip(val_idx, y_val, val_probs):\n",
    "        if gt == 1 and prob[1] < 0.5:\n",
    "            pos_low_conf.append(idx)\n",
    "        elif gt == 0 and prob[1] >= 0.5:\n",
    "            neg_high_conf.append(idx)\n",
    "    global_pos_low_confidence.extend(pos_low_conf)\n",
    "    global_neg_high_confidence.extend(neg_high_conf)\n",
    "    \n",
    "    print(f\"Epoch Final Metrics | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train AUC: {train_auc:.4f} | Train Acc: {train_acc:.4f} || \"\n",
    "          f\"Val Loss: {val_loss:.4f} | Val AUC: {val_auc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# ------------------------------\n",
    "# Save Low-Confidence Predictions\n",
    "# ------------------------------\n",
    "df_pos = meta_data.iloc[global_pos_low_confidence].copy()\n",
    "df_pos['Issue'] = 'Positive predicted prob < 0.5'\n",
    "df_neg = meta_data.iloc[global_neg_high_confidence].copy()\n",
    "df_neg['Issue'] = 'Negative predicted prob >= 0.5'\n",
    "df_subset = pd.concat([df_pos, df_neg])\n",
    "df_subset.to_excel(f\"low_confidence_{label}_predictions.xlsx\", index=False)\n",
    "\n",
    "# ------------------------------\n",
    "# Create and Save Summary Metrics DataFrame\n",
    "# ------------------------------\n",
    "summary_results = pd.DataFrame({\n",
    "    \"Fold\": np.arange(1, n_splits+1),\n",
    "    \"Train Loss\": fold_train_losses,\n",
    "    \"Train AUC\": fold_train_aucs,\n",
    "    \"Train Accuracy\": fold_train_accuracies,\n",
    "    \"Train F1\": fold_train_f1s,\n",
    "    \"Train Precision\": fold_train_precision,\n",
    "    \"Train Recall\": fold_train_recall,\n",
    "    \"Val Loss\": fold_val_losses,\n",
    "    \"Val AUC\": fold_val_aucs,\n",
    "    \"Val Accuracy\": fold_val_accuracies,\n",
    "    \"Val F1\": fold_val_f1s,\n",
    "    \"Val Precision\": fold_val_precision,\n",
    "    \"Val Recall\": fold_val_recall\n",
    "})\n",
    "summary_avg_std = pd.DataFrame([{\n",
    "    \"Fold\": \"Mean ± Std\",\n",
    "    \"Train Loss\": f\"{np.mean(fold_train_losses):.4f} ± {np.std(fold_train_losses):.4f}\",\n",
    "    \"Train AUC\": f\"{np.mean(fold_train_aucs):.4f} ± {np.std(fold_train_aucs):.4f}\",\n",
    "    \"Train Accuracy\": f\"{np.mean(fold_train_accuracies):.4f} ± {np.std(fold_train_accuracies):.4f}\",\n",
    "    \"Train F1\": f\"{np.mean(fold_train_f1s):.4f} ± {np.std(fold_train_f1s):.4f}\",\n",
    "    \"Train Precision\": f\"{np.mean(fold_train_precision):.4f} ± {np.std(fold_train_precision):.4f}\",\n",
    "    \"Train Recall\": f\"{np.mean(fold_train_recall):.4f} ± {np.std(fold_train_recall):.4f}\",\n",
    "    \"Val Loss\": f\"{np.mean(fold_val_losses):.4f} ± {np.std(fold_val_losses):.4f}\",\n",
    "    \"Val AUC\": f\"{np.mean(fold_val_aucs):.4f} ± {np.std(fold_val_aucs):.4f}\",\n",
    "    \"Val Accuracy\": f\"{np.mean(fold_val_accuracies):.4f} ± {np.std(fold_val_accuracies):.4f}\",\n",
    "    \"Val F1\": f\"{np.mean(fold_val_f1s):.4f} ± {np.std(fold_val_f1s):.4f}\",\n",
    "    \"Val Precision\": f\"{np.mean(fold_val_precision):.4f} ± {np.std(fold_val_precision):.4f}\",\n",
    "    \"Val Recall\": f\"{np.mean(fold_val_recall):.4f} ± {np.std(fold_val_recall):.4f}\"\n",
    "}])\n",
    "summary_results = pd.concat([summary_results, summary_avg_std], ignore_index=True)\n",
    "summary_results.to_excel(f\"{label}_metrics_summary.xlsx\", index=False)\n",
    "print(\"\\n=== Cross-Validation Summary ===\")\n",
    "pd.DataFrame(summary_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0484ec3-e3ec-4c78-bbe8-7c551a034850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define common false positive rate grid for interpolation\n",
    "fpr_common = np.linspace(0, 1, 100)\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# ------------------------------\n",
    "# Top Left: Training ROC Curve\n",
    "# ------------------------------\n",
    "tprs_train = []\n",
    "for i, (fpr_i, tpr_i) in enumerate(roc_curves_train):\n",
    "    interp_tpr = np.interp(fpr_common, fpr_i, tpr_i)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs_train.append(interp_tpr)\n",
    "    axs[0, 0].plot(fpr_i, tpr_i, lw=1, alpha=0.3, label=f'Fold {i+1}')\n",
    "mean_tpr_train = np.mean(tprs_train, axis=0)\n",
    "std_tpr_train  = np.std(tprs_train, axis=0)\n",
    "mean_auc_train = np.mean(fold_train_aucs)\n",
    "std_auc_train  = np.std(fold_train_aucs)\n",
    "axs[0, 0].plot(fpr_common, mean_tpr_train, color='blue', lw=2,\n",
    "               label=f'Mean ROC (AUC = {mean_auc_train:.2f} ± {std_auc_train:.2f})')\n",
    "axs[0, 0].fill_between(fpr_common, mean_tpr_train - std_tpr_train,\n",
    "                       mean_tpr_train + std_tpr_train, color='blue', alpha=0.2)\n",
    "axs[0, 0].plot([0, 1], [0, 1], linestyle='--', color='red', label='_nolegend_')\n",
    "axs[0, 0].set_title('Training ROC Curve')\n",
    "axs[0, 0].set_xlabel('False Positive Rate')\n",
    "axs[0, 0].set_ylabel('True Positive Rate')\n",
    "axs[0, 0].legend(loc=\"lower right\")\n",
    "\n",
    "# ------------------------------\n",
    "# Top Right: Validation ROC Curve\n",
    "# ------------------------------\n",
    "tprs_val = []\n",
    "for i, (fpr_i, tpr_i) in enumerate(roc_curves_val):\n",
    "    interp_tpr = np.interp(fpr_common, fpr_i, tpr_i)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs_val.append(interp_tpr)\n",
    "    axs[0, 1].plot(fpr_i, tpr_i, lw=1, alpha=0.3, label=f'Fold {i+1}')\n",
    "mean_tpr_val = np.mean(tprs_val, axis=0)\n",
    "std_tpr_val  = np.std(tprs_val, axis=0)\n",
    "mean_auc_val = np.mean(fold_val_aucs)\n",
    "std_auc_val  = np.std(fold_val_aucs)\n",
    "axs[0, 1].plot(fpr_common, mean_tpr_val, color='blue', lw=2,\n",
    "               label=f'Mean ROC (AUC = {mean_auc_val:.2f} ± {std_auc_val:.2f})')\n",
    "axs[0, 1].fill_between(fpr_common, mean_tpr_val - std_tpr_val,\n",
    "                       mean_tpr_val + std_tpr_val, color='blue', alpha=0.2)\n",
    "axs[0, 1].plot([0, 1], [0, 1], linestyle='--', color='red', label='_nolegend_')\n",
    "axs[0, 1].set_title('Validation ROC Curve')\n",
    "axs[0, 1].set_xlabel('False Positive Rate')\n",
    "axs[0, 1].set_ylabel('True Positive Rate')\n",
    "axs[0, 1].legend(loc=\"lower right\")\n",
    "\n",
    "# ------------------------------\n",
    "# Bottom Left: Training Probability Distribution\n",
    "# ------------------------------\n",
    "# Concatenate probabilities and true labels (assumed pre-collected)\n",
    "train_probs_all = np.concatenate(all_train_probs_1_list)\n",
    "train_targets_all = np.concatenate(all_train_targets_list)\n",
    "# Separate probabilities by true label.\n",
    "train_probs_0 = train_probs_all[train_targets_all == 0]\n",
    "train_probs_1 = train_probs_all[train_targets_all == 1]\n",
    "\n",
    "axs[1, 0].hist(train_probs_0, bins=30, alpha=0.6, color='blue', label='True Class 0')\n",
    "axs[1, 0].hist(train_probs_1, bins=30, alpha=0.6, color='red', label='True Class 1')\n",
    "axs[1, 0].set_title(\"Training Set Probability Distribution\")\n",
    "axs[1, 0].set_xlabel(\"Predicted Probability for Class 1\")\n",
    "axs[1, 0].set_ylabel(\"Frequency\")\n",
    "axs[1, 0].legend()\n",
    "\n",
    "# ------------------------------\n",
    "# Bottom Right: Validation Probability Distribution\n",
    "# ------------------------------\n",
    "val_probs_all = np.concatenate(all_val_probs_1_list)\n",
    "val_targets_all = np.concatenate(all_val_targets_list)\n",
    "# Separate probabilities by true label.\n",
    "val_probs_0 = val_probs_all[val_targets_all == 0]\n",
    "val_probs_1 = val_probs_all[val_targets_all == 1]\n",
    "\n",
    "axs[1, 1].hist(val_probs_0, bins=30, alpha=0.6, color='blue', label='True Class 0')\n",
    "axs[1, 1].hist(val_probs_1, bins=30, alpha=0.6, color='red', label='True Class 1')\n",
    "axs[1, 1].set_title(\"Validation Set Probability Distribution\")\n",
    "axs[1, 1].set_xlabel(\"Predicted Probability for Class 1\")\n",
    "axs[1, 1].set_ylabel(\"Frequency\")\n",
    "axs[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{label}_roc_and_prob.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406e5e94-58fb-4d7a-a4ec-0a8cbb4883c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Convert NumPy types in the class distribution to native Python types\n",
    "native_class_distribution = {\n",
    "    str(k): int(v) if isinstance(v, (np.integer, np.int64)) else v \n",
    "    for k, v in class_distribution.items()\n",
    "}\n",
    "\n",
    "# Collect hyperparameters in a dictionary\n",
    "hyperparameters = {\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"output_dim\": output_dim,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"weight_decay\": weight_decay,            # as used in the optimizer\n",
    "    \"lr_scheduler_gamma\": gamma,      # gamma for ExponentialLR\n",
    "    \"device\": str(device)\n",
    "}\n",
    "\n",
    "# Create a dictionary with model and task information\n",
    "info = {\n",
    "    \"Task\": label,                                   # Task/label\n",
    "    \"Classifier\": net.module.__name__,          # Classifier name\n",
    "    \"Hyperparameters\": hyperparameters,              # Hyperparameters dictionary\n",
    "    \"Class Distribution\": native_class_distribution, # Class distribution\n",
    "    \"Cross-Validation Folds\": n_splits,              # Number of folds used in CV\n",
    "    \"Metrics Summary\": summary_results.to_dict(orient=\"list\")\n",
    "}\n",
    "\n",
    "# Write all the information to a text file\n",
    "with open('Readme.txt', 'w') as f:\n",
    "    f.write(\"Model and Task Information\\n\")\n",
    "    f.write(\"==========================\\n\\n\")\n",
    "    \n",
    "    f.write(\"Task: \" + str(info[\"Task\"]) + \"\\n\\n\")\n",
    "    f.write(\"Classifier: \" + info[\"Classifier\"] + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"Hyperparameters:\\n\")\n",
    "    f.write(json.dumps(info[\"Hyperparameters\"], indent=4))\n",
    "    f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"Class Distribution:\\n\")\n",
    "    f.write(json.dumps(info[\"Class Distribution\"], indent=4))\n",
    "    f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"Cross-Validation Folds: \" + str(info[\"Cross-Validation Folds\"]) + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"Metrics Summary:\\n\")\n",
    "    # Convert summary_results DataFrame to a string for saving\n",
    "    f.write(summary_results.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806bf4b-55af-4ff9-a810-cf871f96b645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RadOmics",
   "language": "python",
   "name": "radomics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
